{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "10d02f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "1.20.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "358b3772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c903c01",
   "metadata": {},
   "source": [
    "## 데이터 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58816775",
   "metadata": {},
   "source": [
    "### 데이터 불러오기 + Resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "03dc0ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115  images to be resized.\n",
      "1115  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = ('/Users/user/aiffel/project/rock_scissor_paper/scissor')\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1813868f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1293  images to be resized.\n",
      "1293  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = ('/Users/user/aiffel/project/rock_scissor_paper/rock')\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e2c325bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980  images to be resized.\n",
      "980  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = ('/Users/user/aiffel/project/rock_scissor_paper/paper')\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83064d2",
   "metadata": {},
   "source": [
    "* 가위, 바위, 보 데이터를 읽을 수 있는 load_dat()함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b9a52128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3388 입니다.\n",
      "x_train shape: (3388, 28, 28, 3)\n",
      "y_train shape: (3388,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=3388):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = ('/Users/user/aiffel/project/rock_scissor_paper')\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539c7802",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "63d6bd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 26, 26, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 13, 13, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 11, 11, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 5, 5, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                204864    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 280,707\n",
      "Trainable params: 280,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06af9c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "106/106 [==============================] - 2s 13ms/step - loss: 0.9167 - accuracy: 0.5549\n",
      "Epoch 2/15\n",
      "106/106 [==============================] - 1s 13ms/step - loss: 0.4651 - accuracy: 0.8247\n",
      "Epoch 3/15\n",
      "106/106 [==============================] - 1s 13ms/step - loss: 0.2060 - accuracy: 0.9324\n",
      "Epoch 4/15\n",
      "106/106 [==============================] - 1s 13ms/step - loss: 0.1053 - accuracy: 0.9681\n",
      "Epoch 5/15\n",
      "106/106 [==============================] - 1s 13ms/step - loss: 0.0572 - accuracy: 0.9861\n",
      "Epoch 6/15\n",
      "106/106 [==============================] - 1s 13ms/step - loss: 0.0401 - accuracy: 0.9891\n",
      "Epoch 7/15\n",
      "106/106 [==============================] - 1s 13ms/step - loss: 0.0250 - accuracy: 0.9938\n",
      "Epoch 8/15\n",
      "106/106 [==============================] - 1s 13ms/step - loss: 0.0149 - accuracy: 0.9973\n",
      "Epoch 9/15\n",
      "106/106 [==============================] - 1s 13ms/step - loss: 0.0110 - accuracy: 0.9982\n",
      "Epoch 10/15\n",
      "106/106 [==============================] - 1s 13ms/step - loss: 0.0075 - accuracy: 0.9985\n",
      "Epoch 11/15\n",
      "106/106 [==============================] - 1s 13ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "106/106 [==============================] - 1s 13ms/step - loss: 0.0034 - accuracy: 0.9994\n",
      "Epoch 13/15\n",
      "106/106 [==============================] - 1s 13ms/step - loss: 0.0192 - accuracy: 0.9947\n",
      "Epoch 14/15\n",
      "106/106 [==============================] - 1s 13ms/step - loss: 0.0064 - accuracy: 0.9988\n",
      "Epoch 15/15\n",
      "106/106 [==============================] - 1s 13ms/step - loss: 0.0020 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ac1becb490>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train , epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b4592",
   "metadata": {},
   "source": [
    "### Test data 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e7473483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=600   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color, dtype=np.int32).reshape(number_of_data, img_size, img_size, color)\n",
    "    labels=np.zeros(number_of_data, dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2ffd4f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user/aiffel/project/rock_scissor_paper/test\n",
      "가위 이미지 resize 완료!\n",
      "바위 이미지 resize 완료!\n",
      "보 이미지 resize 완료!\n",
      "(600, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "test_image_dir_path = ('/Users/user/aiffel/project/rock_scissor_paper/test')\n",
    "print(test_image_dir_path)\n",
    "\n",
    "# scissor\n",
    "t_s_images=glob.glob(test_image_dir_path + \"/scissor/*.jpg\")  \n",
    "target_size=(28,28)\n",
    "for img in t_s_images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "# rock\n",
    "t_r_images=glob.glob(test_image_dir_path + \"/rock/*.jpg\")  \n",
    "target_size=(28,28)\n",
    "for img in t_r_images:\n",
    "    old_img = Image.open(img)\n",
    "    new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    " \n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "# paper\n",
    "t_p_images=glob.glob(test_image_dir_path + \"/paper/*.jpg\")  \n",
    "target_size=(28,28)\n",
    "for img in t_p_images:\n",
    "    old_img = Image.open(img)\n",
    "    new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "    new_img.save(img, \"JPEG\")\n",
    " \n",
    "print(\"보 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "(x_test, y_test)=load_test(test_image_dir_path)\n",
    "x_test_norm = x_test/255.0\n",
    "\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef1fee4",
   "metadata": {},
   "source": [
    "###  모델 테스트 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4860601d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 - 0s - loss: 6.7558 - accuracy: 0.4917 - 150ms/epoch - 8ms/step\n",
      "test_loss: 6.755769729614258 \n",
      "test_accuracy: 0.49166667461395264\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216e6845",
   "metadata": {},
   "source": [
    "### 느낀점...\n",
    "\n",
    "데이터를 점점 늘리면 늘릴수록 점수가 낮아졌다...\n",
    "느낀점은 가위바위보 이미지의 방향이나 컴퓨터가 인식하려고 할때 방해 요소가 있으면 그 데이터의 양이 어마어마하게 방대하지 않은 한 정확하게 인식하지 못한다는 느낌이다. \n",
    "중간에 데이터의 수를 그저 많이 늘려보다가 점수가 너무 나오지 않아 너무 다르게 생긴 데이터들을 조금 삭제해 보았다. 이렇게 했을 때, 점수가 높아진다면 흠....그래도 정상적으로 작동을 하는구나라는 생각에 그렇게 했는데, 점수가 조금은 높게 나왔다. 딥러닝은 너무 어렵다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7c992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
